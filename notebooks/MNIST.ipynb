{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xraydog999/conda-xray/blob/main/notebooks/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJsUjs19_v63"
      },
      "source": [
        "# MNIST with SciKit-Learn and skorch\n",
        "\n",
        "This notebooks shows how to define and train a simple Neural-Network with PyTorch and use it via skorch with SciKit-Learn.\n",
        "\n",
        "<table align=\"left\"><td>\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/skorch-dev/skorch/blob/master/notebooks/MNIST.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>  \n",
        "</td><td>\n",
        "<a target=\"_blank\" href=\"https://github.com/skorch-dev/skorch/blob/master/notebooks/MNIST.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zmIlvxI_v68"
      },
      "source": [
        "**Note**: If you are running this in [a colab notebook](https://colab.research.google.com/github/skorch-dev/skorch/blob/master/notebooks/MNIST.ipynb), we recommend you enable a free GPU by going:\n",
        "\n",
        "> **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**\n",
        "\n",
        "If you are running in colab, you should install the dependencies and download the dataset by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://colab.research.google.com/github/skorch-dev/skorch/blob/master/notebooks/MNIST.ipynb"
      ],
      "metadata": {
        "id": "38i2Tllv9Us3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8qYGNO2S_v6_"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "# Installation on Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    subprocess.run(['python', '-m', 'pip', 'install', 'skorch' , 'torch'])\n",
        "except ImportError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Gj0pvjxT_v7G"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPz6Bjqw_v7H"
      },
      "source": [
        "## Loading Data\n",
        "Using SciKit-Learns ```fetch_openml``` to load MNIST data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mwpfASvc_v7J"
      },
      "outputs": [],
      "source": [
        "mnist = fetch_openml('mnist_784', as_frame=False, cache=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9Pt2JKyb_v7K",
        "outputId": "32da2200-b1f8-4ae5-ca57-5cad224812f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "mnist.data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV0ehb52_v7L"
      },
      "source": [
        "## Preprocessing Data\n",
        "\n",
        "Each image of the MNIST dataset is encoded in a 784 dimensional vector, representing a 28 x 28 pixel image. Each pixel has a value between 0 and 255, corresponding to the grey-value of a pixel.<br />\n",
        "The above ```featch_mldata``` method to load MNIST returns ```data``` and ```target``` as ```uint8``` which we convert to ```float32``` and ```int64``` respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "F2v_Fwne_v7M"
      },
      "outputs": [],
      "source": [
        "X = mnist.data.astype('float32')\n",
        "y = mnist.target.astype('int64')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_yHJarZ_v7N"
      },
      "source": [
        "To avoid big weights that deal with the pixel values from between [0, 255], we scale `X` down. A commonly used range is [0, 1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8RirCOTr_v7O"
      },
      "outputs": [],
      "source": [
        "X /= 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rohyp3d1_v7P",
        "outputId": "a99508e9-0d79-46e3-fe0f-b1ba3bd6fa5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float32(0.0), np.float32(1.0))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "X.min(), X.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyUlsu0V_v7Q"
      },
      "source": [
        "Note: data is not normalized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gILlsHJS_v7R"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jGpA4v4u_v7R"
      },
      "outputs": [],
      "source": [
        "assert(X_train.shape[0] + X_test.shape[0] == mnist.data.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "plXmcsp2_v7b",
        "outputId": "a45d23c8-d154-407a-dfbf-7e6341e4031d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((52500, 784), (52500,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EKEvbuP_v7c"
      },
      "source": [
        "### Print a selection of training images and their labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "C9muXJPC_v7d"
      },
      "outputs": [],
      "source": [
        "def plot_example(X, y):\n",
        "    \"\"\"Plot the first 5 images and their labels in a row.\"\"\"\n",
        "    for i, (img, y) in enumerate(zip(X[:5].reshape(5, 28, 28), y[:5])):\n",
        "        plt.subplot(151 + i)\n",
        "        plt.imshow(img)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "h2-R1-Df_v7e",
        "outputId": "c17d8535-6e5b-47d7-a5c6-c0630c11e968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_example(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQvC-rWf_v7f"
      },
      "source": [
        "## Build Neural Network with PyTorch\n",
        "Simple, fully connected neural network with one hidden layer. Input layer has 784 dimensions (28x28), hidden layer has 98 (= 784 / 8) and output layer 10 neurons, representing digits 0 - 9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5PG7R0W8_v7f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NUjWrGBP_v7g"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gVCW8F3N_v7g"
      },
      "outputs": [],
      "source": [
        "mnist_dim = X.shape[1]\n",
        "hidden_dim = int(mnist_dim/8)\n",
        "output_dim = len(np.unique(mnist.target))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ShYicHlv_v7h",
        "outputId": "02cf4d69-33ce-4a09-8d87-6e8f44002e85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 98, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "mnist_dim, hidden_dim, output_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeVnFhBS_v7i"
      },
      "source": [
        "A Neural network in PyTorch's framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Xxtli0l__v7j"
      },
      "outputs": [],
      "source": [
        "class ClassifierModule(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_dim=mnist_dim,\n",
        "            hidden_dim=hidden_dim,\n",
        "            output_dim=output_dim,\n",
        "            dropout=0.5,\n",
        "    ):\n",
        "        super(ClassifierModule, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
        "        self.output = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, X, **kwargs):\n",
        "        X = F.relu(self.hidden(X))\n",
        "        X = self.dropout(X)\n",
        "        X = F.softmax(self.output(X), dim=-1)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlEHSwjt_v7k"
      },
      "source": [
        "skorch allows to use PyTorch's networks in the SciKit-Learn setting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "s0aDatqN_v7l"
      },
      "outputs": [],
      "source": [
        "from skorch import NeuralNetClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dOrCbBjk_v7m"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "net = NeuralNetClassifier(\n",
        "    ClassifierModule,\n",
        "    max_epochs=20,\n",
        "    lr=0.1,\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8i_gnvPi_v7m",
        "outputId": "1992f62d-65dd-4fd8-f56f-9bfea973d341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.8387\u001b[0m       \u001b[32m0.8800\u001b[0m        \u001b[35m0.4174\u001b[0m  1.3670\n",
            "      2        \u001b[36m0.4332\u001b[0m       \u001b[32m0.9103\u001b[0m        \u001b[35m0.3133\u001b[0m  0.8063\n",
            "      3        \u001b[36m0.3612\u001b[0m       \u001b[32m0.9233\u001b[0m        \u001b[35m0.2684\u001b[0m  0.7914\n",
            "      4        \u001b[36m0.3233\u001b[0m       \u001b[32m0.9309\u001b[0m        \u001b[35m0.2317\u001b[0m  0.8407\n",
            "      5        \u001b[36m0.2938\u001b[0m       \u001b[32m0.9353\u001b[0m        \u001b[35m0.2173\u001b[0m  0.7928\n",
            "      6        \u001b[36m0.2738\u001b[0m       \u001b[32m0.9390\u001b[0m        \u001b[35m0.2039\u001b[0m  0.7936\n",
            "      7        \u001b[36m0.2600\u001b[0m       \u001b[32m0.9454\u001b[0m        \u001b[35m0.1868\u001b[0m  0.7958\n",
            "      8        \u001b[36m0.2427\u001b[0m       \u001b[32m0.9484\u001b[0m        \u001b[35m0.1757\u001b[0m  0.8015\n",
            "      9        \u001b[36m0.2362\u001b[0m       \u001b[32m0.9503\u001b[0m        \u001b[35m0.1683\u001b[0m  0.8194\n",
            "     10        \u001b[36m0.2226\u001b[0m       \u001b[32m0.9512\u001b[0m        \u001b[35m0.1621\u001b[0m  0.7875\n"
          ]
        }
      ],
      "source": [
        "net.fit(X_train, y_train);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c3iyCKu_v7m"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7rdey0s_v7n"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9B8Zd6e_v7n"
      },
      "outputs": [],
      "source": [
        "y_pred = net.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCWachuM_v7o"
      },
      "outputs": [],
      "source": [
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eRga6AV_v7o"
      },
      "source": [
        "An accuracy of about 96% for a network with only one hidden layer is not too bad.\n",
        "\n",
        "Let's take a look at some predictions that went wrong:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XddXR1_a_v7p"
      },
      "outputs": [],
      "source": [
        "error_mask = y_pred != y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXlNTrlt_v7q"
      },
      "outputs": [],
      "source": [
        "plot_example(X_test[error_mask], y_pred[error_mask])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2GsBaxH_v7r"
      },
      "source": [
        "# Convolutional Network\n",
        "PyTorch expects a 4 dimensional tensor as input for its 2D convolution layer. The dimensions represent:\n",
        "* Batch size\n",
        "* Number of channel\n",
        "* Height\n",
        "* Width\n",
        "\n",
        "As initial batch size the number of examples needs to be provided. MNIST data has only one channel. As stated above, each MNIST vector represents a 28x28 pixel image. Hence, the resulting shape for PyTorch tensor needs to be (x, 1, 28, 28)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bwsaz88X_v7r"
      },
      "outputs": [],
      "source": [
        "XCnn = X.reshape(-1, 1, 28, 28)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go0Yz8xl_v7s"
      },
      "outputs": [],
      "source": [
        "XCnn.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rt8ETXGa_v7t"
      },
      "outputs": [],
      "source": [
        "XCnn_train, XCnn_test, y_train, y_test = train_test_split(XCnn, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jQm85il_v7t"
      },
      "outputs": [],
      "source": [
        "XCnn_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdQ-ISvb_v7u"
      },
      "outputs": [],
      "source": [
        "class Cnn(nn.Module):\n",
        "    def __init__(self, dropout=0.5):\n",
        "        super(Cnn, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
        "        self.conv2_drop = nn.Dropout2d(p=dropout)\n",
        "        self.fc1 = nn.Linear(1600, 100) # 1600 = number channels * width * height\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "        self.fc1_drop = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = torch.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "\n",
        "        # flatten over channel, height and width = 1600\n",
        "        x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "\n",
        "        x = torch.relu(self.fc1_drop(self.fc1(x)))\n",
        "        x = torch.softmax(self.fc2(x), dim=-1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJrWyFfb_v7u"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "cnn = NeuralNetClassifier(\n",
        "    Cnn,\n",
        "    max_epochs=10,\n",
        "    lr=0.002,\n",
        "    optimizer=torch.optim.Adam,\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRtHfgg8_v7u"
      },
      "outputs": [],
      "source": [
        "cnn.fit(XCnn_train, y_train);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6V7wyzb_v7v"
      },
      "outputs": [],
      "source": [
        "y_pred_cnn = cnn.predict(XCnn_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSyiZ3p6_v7v"
      },
      "outputs": [],
      "source": [
        "accuracy_score(y_test, y_pred_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npZlem33_v7v"
      },
      "source": [
        "An accuracy of >98% should suffice for this example!\n",
        "\n",
        "Let's see how we fare on the examples that went wrong before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oWL0xGC_v7w"
      },
      "outputs": [],
      "source": [
        "accuracy_score(y_test[error_mask], y_pred_cnn[error_mask])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8239U9fF_v7w"
      },
      "source": [
        "Over 70% of the previously misclassified images are now correctly identified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vU1SXeV_v7x"
      },
      "outputs": [],
      "source": [
        "plot_example(X_test[error_mask], y_pred_cnn[error_mask])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-tIl3el_v7x"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "bd97b8bffa4d3737e84826bc3d37be3046061822757ce35137ab82ad4c5a2016"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}